\documentclass{ufscThesis}
\usepackage{graphicx}
\usepackage[labelsep=endash]{caption}
\usepackage{algorithmicx}
\usepackage[Algoritmo,ruled]{algorithm}
\usepackage{algpseudocode}

\newtheorem{definition}{Definição}

\titulo{Método Automático para Segmentação e Remoção de Ruído de
Páginas $web$ Utilizando $tag$ $paths$}
\autor{Roberto Panerai Velloso}
\data{01}{março}{2014}
\orientador[Orientadora]{Profa. Dra. Carina F. Dorneles}
\coordenador{Prof. Dr. Ronaldo dos Santos Mello}


\departamento{Departamento de Informática e Estatística}
\curso{Programa de Pós-Graduação em Ciência da Computação}

\numerodemembrosnabanca{5}
\orientadornabanca{sim}
\bancaMembroA{Prof. Presidente da banca}
\bancaMembroB{Prof. segundo membro}
\bancaMembroC{Prof. terceiro membro}

%\bancaMembroD{Prof. quarto membro}
%\bancaMembroE{Prof. quinto membro}
%\bancaMembroF{Prof. sexto membro}
%\bancaMembroG{Prof. setimo membro}

\dedicatoria{À minha família.}

\agradecimento{Agradeço o apoio dos familiares e a atenção dispensada pelos
professores do curso, em especial pela orientação que recebi para realização e
publicação deste trabalho.}

\epigrafe{ Está instaurada a dúvida.\\
A metódica dúvida epistemológica.\\
Neste mundo a terra não está no centro\\
nenhum saber é saber completo.\\
Seja bem-vinda era da razão.\\
Não há que se temer a revisão.\\
Nada que se diga ou que foi dito\\
merece estatuto de dogma irrestrito.\\
Cuidado com a verdade\\
que se pretende\\
maior que a realidade,\\
pois, os fatos são os fatos\\
e fluem diante de nós\\
que estupefatos\\
assistimos ao espetáculo.}{Galileu Galilei}

\textoResumo{Segmentação e remoção de ruído de páginas $web$ são etapas
essenciais no processo de extração de dados estruturados. Identificar a região
principal da página, eliminando o que não é importante (menus, anúncios, etc.),
pode melhorar significativamente o desempenho do processo de extração. Para essa
tarefa é proposto um novo algoritmo, totalmente automático, que utiliza uma
seqüência $tag$ $paths$ (TPS) como representação da página $web$.
A TPS é composta por uma seqüência de símbolos ($string$), cada um representando
um $tag$ $path$ diferente. A técnica proposta procura por posições na TPS onde é
possível dividi-la em duas regiões de tal forma que seus alfabetos não se
intersectem, o que significa que as regiões têm conjuntos de $tag$ $paths$
completamente distintos e, portanto, são regiões diferentes da página. Os
resultados mostram que o algoritmo é muito efetivo em identificar o conteúdo
principal de vários $sites$, e melhora a precisão da extração, removendo
resultados irrelevantes.}

\palavrasChave{remoção ruído. segmentação página. extração estruturada. mineração dados $web$.}

\textAbstract{Web page segmentation and data cleaning are essential steps in
structured web data extraction. Identifying a web page main content region,
removing what is not important (menus, ads, etc.), can greatly improve the
performance of the extraction process. We propose, for this task, a novel and
fully automatic algorithm that uses a tag path sequence (TPS) representation of
the web page. The TPS consists of a sequence of symbols (string), each one
representing a different tag path.
The proposed technique searches for positions in the TPS where it is possible to
split it in two regions where each region's alphabet do not intersect, which
means that they have completely different sets of tag paths and, thus, are
different regions. The results show that the algorithm is very effective in
identifying the main content block of several major web sites, and improves the
precision of the extraction step by removing irrelevant results.
}

\keywords{noise removal. page segmentation. structured extraction. web mining}

\begin{document}

\capa  
\folhaderosto[comficha]
\folhaaprovacao
\paginadedicatoria
\paginaagradecimento
\paginaepigrafe
\paginaresumo
\paginaabstract

\listadefiguras
\listadetabelas 
\listadeabreviaturas
%\listadesimbolos
\sumario

\chapter{Introdução}
%\section{Contextualização do problema}

Um passo fundamental da mineração de dados na $web$, inclusive em extração
estruturada, é a fase de limpeza que deve ocorrer antes da extração da
informação. Não se pode esperar bons resultados na fase de extração sem efetuar
a limpeza da página, removendo o ruído indesejado. Em \citeonline{Noisy03}, é
mencionado que apesar da importância desta tarefa, existem relativamente poucos
trabalhos nesta área e, de acordo com \citeonline{Editorial04}, o ruído
existente nas páginas pode prejudicar consideravelmente a mineração de dados na
$web$.

Na extração estruturada, a maioria das técnicas existentes utilizam algum tipo
de reconhecimento de padrão para identificar os registros (como definido em
\citeonline{MDR03}) presentes nas páginas. O problema é que, em geral, apenas os
registros da região principal da página interessam, porém outras regiões da
página (menus, anúncios, etc.) freqüentemente contém padrões que também são
extraídos ($e.g.$ Figura \ref{fig:exr}). Portanto, é importante efetuar a
limpeza das páginas $web$ antes de extrair seu conteúdo estruturado.

\begin{figure}[H]
  \centering
    \includegraphics[scale=0.22]{exemploruido.jpg}
  \caption{Exemplo de uma página de comércio eletrônico com os registros e
  ruído identificados.}
  \label{fig:exr}
\end{figure}


Atualmente, alguns trabalhos na área de remoção de ruído e segmentação são
direcionados para indexação e $clustering$ de páginas ($i.e.$ é assumido que a
região principal é textual/não estruturada) como em
\citeonline{SiteOriented11,Noisy03} e, devido às diferenças intrínsecas entre
conteúdo estruturado e não estruturado, estas técnicas não podem ser utilizadas
para extração estruturada. As técnicas existentes que podem ser utilizadas para
este fim requerem definições \textit{a priori} \cite{vips03}, ou treinamento
prévio \cite{Graph08}, ou então dependem de aspectos específicos da linguagem
\abreviatura{HTML}{hypertext markup language}HTML para funcionar, como em
\citeonline{Entropy09}.

O presente trabalho descreve um algoritmo para segmentação e remoção de ruído de
páginas $web$ que utiliza a representação de seqüência de $tag$ $paths$ de uma
página e que é simples e computacionalmente eficiente.
Trata-se de uma técnica geral de segmentação de páginas, utilizada aqui no
contexto de extração estruturada, levando em consideração o estilo e a estrutura
da página. As principais contribuições são as seguintes:

\begin{itemize}
\item{Totalmente automática}: não necessita de treinamento nem intervenção
humana;
\item{Independente de domínio}: o único requisito é que a página possua
conteúdo estruturado, não importando a que domínio pertença;
\item{Independente da sintaxe HTML}: não existem regras associadas a $tags$
HTML específicas;
\item{Funciona em uma página}: é necessária apenas uma página como entrada, o
que constitui uma grande vantagem desta proposta, como discutido em
\citeonline{Editorial04}.
\end{itemize}

Para avaliar o quão efetivo é o método proposto neste trabalho, foi comparado
o ruído de saída do \abreviatura{MDR}{mine data records}MDR \cite{MDR03}, uma
conhecida técnica de extração estruturada, contra o ruído de saída do MDR
combinado com a técnica proposta, como ilustrado na Figura \ref{fig:method},
obtendo-se uma média de 88,86\% de ruído removido das páginas do conjunto de
teste.

\begin{figure}[H]
  \centering
    \includegraphics[scale=0.22]{metodo.jpg}
  \caption{Método de avaliação adotado.}
  \label{fig:method}
\end{figure}

Durante a discussão dos resultados, são apresentadas e discutidas, também, as
situações em que o método não obteve sucesso (total ou parcial). São apontadas
as causas e sugeridas maneiras de se atacar as limitações identificadas durante
a realização dos experimentos.

Esta dissertação está organizada da seguinte maneira: %no Capítulo
% \ref{ch:obj} são apresentados os objetivos da pesquisa; no Capítulo
% \ref{ch:contr} são enunciadas as principais contribuições do trabalho;
no Capítulo \ref{ch:rev} é feita uma revisão dos trabalhos relacionados,
observando as limitações das propostas existentes para solução do problema; no
Capítulo \ref{ch:met} são enunciadas as definições necessárias ao entendimento
da proposta e são detalhados e ilustrados os algoritmos desenvolvidos a partir
da formulação do problema e das hipóteses; no Capítulo \ref{ch:results} o método de
avaliação dos resultados é detalhado e também são apresentados os resultados
obtidos e as limitações do método proposto e, finalmente; no Capítulo
\ref{ch:conclusion} uma breve conclusão e sugestões de trabalhos futuros.

%\section{Objetivos}\label{ch:obj}

%O objetivo desta pesquisa é contribuir para área de extração estruturada de
%dados da $web$, propondo uma nova técnica para segmentação e remoção de ruído
% de páginas que possibilite incrementar a precisão dos métodos atuais, com o mínimo
%de intervenção manual e o máximo de independência com relação a aspectos da
%linguagem HTML e ao domínio da informação.

%\section{Contribuições}\label{ch:contr}

%A contribuição desta pesquisa é uma nova técnica de segmentação e remoção de
%ruído de páginas $web$ com as seguintes características:
%\begin{itemize}
%\item{Técnica completamente automática}: não é necessário treinamento nem
%intervenção humana;
%\item{Independente de domínio}: é necessário apenas que a página contenha
%conteúdo estruturado, não importando a que domínio a informação pertence;
%\item{Independente da sintaxe HTML}: não são utilizadas regras associadas a
%$tags$ HTML;
%\item{Necessita de apenas uma página}: não requer várias páginas do mesmo
% $site$ para funcionar, o que é um grande vantagem, como discutido em
%\citeonline{Editorial04}.
%\end{itemize}

\chapter{Trabalhos relacionados}\label{ch:rev}

Existem muitos trabalhos propondo formas de segmentar páginas $web$ e
identificar o que é conteúdo e o que é ruído nelas. Elas podem ser agrupadas em
três categorias: as que se baseiam no texto da página, as que se baseiam na
árvore \abreviatura{DOM}{document object model}DOM e as que utilizam informação
visual.

\textbf{Técnicas baseadas no texto}. Em
\citeonline{Densiometric08,Boilerplate10,CETR10,BlockImp07,NonTemplate13} a
segmentação é realizada utilizando o conteúdo textual da página $web$. O foco
destes trabalhos, entretanto, não é em extração estruturada, mas em indexação e
$clustering$ de páginas. A maioria dos trabalhos existentes sobre segmentação e
remoção de ruído são direcionados para este tipo de aplicação.

\textbf{Técnicas baseadas na árvore DOM}. Em
\citeonline{Entropy09,SiteOriented11,Graph08,Noisy03,Entropy12,desc2013} a
segmentação é realizada utilizando a árvore DOM da página, portanto, estas técnicas levam em
consideração a estrutura da página $web$. Entretanto,
\citeonline{SiteOriented11} e \citeonline{Noisy03} necessitam de várias páginas
de um mesmo $site$, \citeonline{Graph08} propõe um $framework$ de treinamento
que necessita de dados catalogados manualmente para funcionar,
\citeonline{Entropy12} necessita de uma base de dados de termos associados a
``papéis semânticos'' para poder detectar regiões de dados e 
\citeonline{desc2013} utiliza o algoritmo C4.5, que necessita de treinamento
prévio, para classificar quais nós do DOM são ruídos.

\textbf{Técnicas baseadas em informação visual}.
Além das técnicas baseadas no texto e na árvore DOM da página, existem também
aquelas que utilizam informação visual, como \citeonline{vips03,vide10,viper05}.
Todas dependem de um renderizador de um navegador $web$ para obter as
informações visuais das páginas, o que pode ser computacionalmente dispendioso,
e, além disso, \citeonline{vips03} é baseado em um conjunto de regras
heurísticas, cada uma aplicada a $tags$ HTML específicas. Técnicas que dependem
fortemente de aspectos específicos da linguagem HTML tem a séria desvantagem
de serem afetadas por mudanças nas práticas de desenvolvimento assim como
mudanças na sintaxe da linguagem.

A representação da página $web$ utilizada nesta pesquisa (seqüência de $tag$
$paths$) foi anteriormente empregada em \citeonline{TPC09} e
\citeonline{SuffixTree12}, embora em ambos os casos para a extração e não para
segmentação e remoção de ruído. Estes dois trabalhos são citados aqui apenas
para ilustrar que, de acordo com seus resultados, esta representação, assim como
a árvore DOM, também é capaz de expor a estrutura da página $web$ e, portanto,
serve para os propósitos desta pesquisa.
A Figura \ref{fig:ex1} ilustra como o código HTML de uma página $web$ é
convertido para representação de $tag$ $paths$.

\begin{figure}[h]
  \centering
     \includegraphics[scale=0.51]{example1-pt.jpg}
  \caption{Exemplo de uma seqüência de $tag$ $paths$ construída a partir do código HTML.}
  \label{fig:ex1}
\end{figure}

Na Tabela \ref{table:comp} é feito um comparativo entre as técnicas mais
significativos (neste contexto) revistas e a proposta apresentada, com objetivo
de explicitar as diferenças entre estes trabalhos.

\begin{table}[h]
\centering
\begin{tiny}
\caption{Comparativo entre técnicas de segmentação de página}
\label{table:comp}
\begin{tabular}{c l c c c c c}
\hline\hline
   &          &          & Opera c/ & Necessita & Necessita   & Independe \\
   &          & Opera    & única    & Treina-   & informação  & sintaxe \\ 
\# &Técnica   & sobre    & página   & mento     & a priori    & HTML \\
\hline
1 & \citeonline{BlockImp07} & Texto & - & - & - & - \\
2 & \citeonline{Densiometric08} & Texto & - & - & - & - \\
3 & \citeonline{Boilerplate10} & Texto & - & - & - & - \\
4 & \citeonline{CETR10} & Texto & - & - & - & - \\
5 & \citeonline{NonTemplate13} & Texto & - & - & - & - \\
6 & \citeonline{Noisy03} & DOM & Não & Sim & Não & Não \\
7 & \citeonline{Graph08} & DOM & Não & Sim & Não & Não \\
8 & \citeonline{Entropy09} & DOM & Sim & Não & Sim & Sim \\
9 & \citeonline{SiteOriented11} & DOM & Não & Sim & Não & Não \\
10 & \citeonline{Entropy12} & DOM & Sim & Não & Sim & Sim \\
11 & \citeonline{Jointop07} & DOM & Não & Sim & Não & Não \\
12 & \citeonline{desc2013} & DOM & Não & Sim & Não & Sim \\
13 & \citeonline{vips03} & Visual & Sim & Não & Sim & Sim \\
14 & \citeonline{viper05} & Visual & Sim & Não & Não & Sim \\
15 & \citeonline{vide10} & Visual & Sim & Não & Sim & Sim \\
\hline
16 & \citeonline{TPS2013} & TPS & Sim & Não & Não & Sim \\
\end{tabular}
\end{tiny}
\end{table}

\chapter{Método para remoção de ruído}\label{ch:met}

Neste capítulo são apresentadas, primeiro, as definições necessárias para
formular o problema na Seção \ref{sec:def}. Na Seção \ref{sec:probform} o
problema é enunciado a partir das definições e das hipóteses levantadas. Na
Seção \ref{sec:alg} são apresentados os algoritmos desenvolvidos a partir do
enunciado do problema e na Seção \ref{sec:compl} é feita a análise da
complexidade destes algoritmos.

\section{Definições básicas}\label{sec:def}

Nesta seção são apresentados os conceitos e definições necessários para o
entendimento do problema e do algoritmo proposto. As definições são
exemplificadas com o auxílio da Figura \ref{fig:ex1}.
\begin{definition}[\textbf{Árvore DOM}]\label{def:domtree}
A árvore DOM é uma estrutura hierárquica, derivada do código HTML, que
representa a página $web$.
\end{definition}
Na Figura \ref{fig:ex1} um pequeno trecho de código é utilizado para ilustrar a
árvore DOM e as próximas definições.

\begin{definition}[\textbf{$tag$ $paths$}]\label{def:tp} Um $tag$ $path$
(\abreviatura{TP}{tag path}TP) é uma $string$ descrevendo o caminho absoluto, a
partir da raiz da árvore DOM, até um dado nó da árvore. Seja ``i'' a posição em
profundidade do nó $``n_i"$ na árvore, então é dito que $TP_i$ é a $string$
descrevendo o caminho, a partir da raiz da árvore DOM, até o nó $``n_i"$.
\end{definition}
Na Figura \ref{fig:ex1}, o caminho absoluto $TP_4$ do nó $body$ até a célula da
tabela $td_4$ é $TP_4=``body/table/tr/td"$.

\begin{definition}[\textbf{Seqüência de \textit{$tag$ $paths$}}]\label{def:tps}
Uma seqüência de $tag$ $paths$ (\abreviatura{TPS}{tag path sequence}TPS) de uma
árvore DOM com ``n'' nós é definida como sendo a seqüência ordenada $TPS[1..n] = (TP_1,TP_2,TP_3, ...,TP_{n-1},TP_n)$
onde dois $tag$ $paths$ $TP_i$ e $TP_j$, com $i\neq{}j$, são considerados iguais
apenas se seus caminhos e suas definições de estilo são iguais, caso
contrário eles são considerados diferentes.
\end{definition}
Esta é a mesma definição utilizada em \citeonline{SuffixTree12}, onde cada $tag$
$path$ é representado na seqüência por um símbolo, exceto que neste trabalho
foram incorporadas as definições de estilo das $tags$. Na Figura \ref{fig:ex1}
é mostrada a $TPS$ de um dado trecho de código HTML, onde cada $TP$ recebe um
código, produzindo $TPS = (1,2,3,4,4,3,4,4)$.

\begin{definition}[\textbf{Alfabeto da TPS}]\label{def:alpha} Seja $\Sigma_a$ o
conjunto contendo todos os símbolos de uma dada seqüência $TPS_a$ de tamanho
``n'', $\Sigma_a$ é dito o alfabeto de $TPS_a$ definido como $\Sigma_a =
\{\alpha | \exists{TPS_a[i]}=\alpha \wedge 1 \leq i \leq n\}$, onde $\alpha$ é
um símbolo do alfabeto.
\end{definition}
Informalmente falando, o alfabeto contém todos os símbolos distintos de uma
determinada seqüência. Na Figura \ref{fig:ex1}, a $TPS$ é formada apenas pelos
símbolos ``1'',``2'', ``3'' e ``4'', então seu alfabeto é $\Sigma=\{1,2,3,4\}$.

\begin{definition}[\textbf{Conjunto de freqüências de $tag$ $paths$}]\label{def:tpfs}
Seja $(s,f)$ um par ordenado onde ``s'' é um símbolo de um alfabeto de uma
determinada TPS e ``f'' é o número de vezes que ``s'' ocorre na TPS, então o
conjunto de freqüências de $tag$ $paths$ é definido como sendo o conjunto de
todos os pares $(s,f)$ existentes em uma TPS. Seja $FS =
\{(s_1,f_{s1}),(s_2,f_{s2}),(s_3,f_{s3}),\ldots,(s_{n-1},f_{sn-1}),(s_n,f_{sn})\}$,
onde ``n" é o tamanho da TPS.
\end{definition}
Na Figura \ref{fig:ex1}, o símbolo ``1'' ocorre uma vez na seqüência, o símbolo
``2'' ocorre uma vez também, o símbolo ``3'' duas vezes e o símbolo ``4'' quatro
vezes, então para esta seqüência $FS = \{(1,1), (2,1), (3,2), (4,4)\}$. O
conjunto $FS$ é o mapeamento de todos os símbolos de uma seqüência para suas
respectivas freqüências.

\begin{definition}[\textbf{Limiares de freqüência}]\label{def:ft}
Dada uma $TPS_a$ com alfabeto $\Sigma_a$ e conjunto de freqüências $FS_a$, os
limiares de freqüência $FT_a$ são definidos como sendo o conjunto ordenado
contendo apenas as freqüências de $FS_a$. Seja $FT_a = \{f|\exists{(s,f)} \wedge
(s,f) \in FS_a \wedge s \in \Sigma_a \}$, onde ``f'' é uma freqüência e ``s'' é
o símbolo correspondente do alfabeto $\Sigma_a$.
\end{definition}
Na TPS exibida na Figura \ref{fig:ex1}, o conjunto de freqüências é $FS=\{(1,1),
\\ (2,1), (3,2), (4,4)\}$, neste caso o conjunto dos limiares de freqüência é
igual a $FT=\{1,2,4\}$, pois os símbolos ``1'' e ``2'' tem freqüência igual a
\textbf{1}, o símbolo ``3'' tem freqüência igual a \textit{2} e o símbolo ``4''
tem freqüência igual a \textit{4}. O conjunto $FT$ é necessário para filtrar os
símbolos da TPS. Se $FT=\{1,2,4\}$, então não faria sentido filtrar símbolos com
freqüência igual a \textit{3}, pois não existem símbolos na seqüência com esta
freqüência.

\begin{definition}[\textbf{Região}]\label{def:region} 
Seja uma TPS a concatenação de duas outras seqüências $TPS=TPS_a . TPS_b$, então
é dito que $TPS_a$ e $TPS_b$ são regiões de $TPS$, $sse$ $\Sigma_a \cap \Sigma_b
= \emptyset$.
\end{definition}
Na Figura \ref{fig:ex1} a TPS pode ser dividida em duas subseqüências
$TPS_a=TPS[1..2]=(1,2)$ e $TPS_b=TPS[3..8]=(3,4,4,3,4,4)$, com alfabetos
$\Sigma_a=\{1,2\}$ e $\Sigma_b=\{3,4\}$, então $TPS_a$ a $TPS_b$
são regiões distintas de $TPS$, pois $\Sigma_a \cap \Sigma_b=\emptyset$.

\section{Proposta}\label{sec:probform}

Nesta pesquisa é proposta uma nova técnica para segmentação das regiões de uma
página $web$ e identificação da região principal. A técnica proposta é simples,
computacionalmente eficiente e leva em consideração a estrutura e os estilos de
formatação das páginas. A página $web$ é representada na forma de $tag$ $paths$.
É um método de segmentação genérico, utilizado aqui no contexto da extração
estruturada.

O algoritmo proposto é formulado a partir de duas hipóteses:
\begin{enumerate}
  \item\label{ass:1} diferentes regiões de uma página $web$ são descritas por
  diferentes $tag$ $paths$;
  \item\label{ass:2} em $sites$ com conteúdo estruturado, a região
  principal é mais densa/maior que as demais regiões (menus, anúncios, text, etc.). 
\end{enumerate}

A formulação da Hipótese \ref{ass:1} vem da observação de que as várias regiões
de uma página $web$ são diferentes ramificações da árvore DOM e essas regiões
são descritas ou utilizando $tags$ distintas para cada região ou, se as $tags$
forem semelhantes, com diferentes estilos, para que cada região possa ser
facilmente distinguida pelo usuário/leitor da página. Se todas as regiões de uma
página se parecessem, seria mais difícil, para o usuário, distingui-las.
Então, pela Definição \ref{def:tps}, pode-se notar que os símbolos utilizadas em
cada região de uma página $web$ deveriam ser diferentes, e então deve ser
possível segmentar a página como na Definição \ref{def:region}.

A Hipótese \ref{ass:2} vem do contexto no qual a segmentação proposta neste
trabalho é aplicada ($i.e.$ extração estruturada). Como se está considerando
apenas páginas com registros, e para descrever a estrutura desses registros são
necessários nós da árvore DOM, então são necessários mais nós para descrever
conteúdo estruturado do que é necessário para conteúdo não estruturado ($e.g.$
texto). Portanto, é razoável assumir que, para páginas que contém registros, a
região principal da página é a maior de todas ($i.e.$ a que contém mais nós).

Utilizando as definições da Seção \ref{sec:def} e as hipóteses acima,
podemos formular o problema de segmentação de páginas e identificação da região
principal como: \textbf{``encontrar a maior \textit{região} da $TPS$ de uma
página $web$ que possua um $alfabeto$ que não se intersecte com o $alfabeto$ de
outras \textit{regiões} menores''}.

Um detalhe \textbf{crucial} que deve ser levado em consideração, é que podem
existir $tag$ $paths$ em uma página que representam divisões estruturais da
página ($i.e.$ formatação visual da página). Estes $tag$ $paths$, se forem
divisões, ocorrerão ao longo de toda a $TPS$, impedindo a identificação das
regiões, pois sempre haverá uma intersecção dos alfabetos. Para remover este
``ruído'' da seqüência, podemos filtrar os símbolos com freqüências mais baixas,
sem prejudicar o processo de segmentação, pois os símbolos com freqüências mais
altas continuam sendo considerados.

Apenas para ilustrar, é apresentado um exemplo de uma página $web$ que inicia e
termina com o mesmo $tag$ $path$ (``/body/br'') e tem três regiões delimitadas,
também, pelo mesmo $tag$ $path$ (``/body/div''). Assumindo que diferentes $tag$
$paths$ são utilizados para descrever cada região, sem filtrar os símbolos de
baixa freqüência da $TPS$, não seria possível identificar essas regiões.

\begin{itemize}
\item{código HTML}
\begin{small} 
\begin{verbatim}
<body>
<br> <!-- cabeçalho -->
<div> <!-- menu -->
  <span class='region1'>...</span>
  ...
  <span class='region1'>...</span>
</div> 
<div> <!-- região principal -->
  <span class='region2'>...</span>
  ...
  <span class='region2'>...</span>
</div>
<div> <!-- publicidade -->
  <span class='region3'>...</span>
  ...
  <span class='region3'>...</span>
</div>
<br> <!-- rodapé -->
</body>
\end{verbatim}
\end{small}
\item{TPS}
\begin{verbatim}
TPS = (1,2,3,4,...,4,3,5,...,5,3,6,...,6,2)
\end{verbatim}

Os símbolos $2$ e $3$ ocorrem ao longo de toda a $TPS$.

\item{TPS filtrada}
\begin{verbatim}
TPS = ( , , ,4,...,4, ,5,...,5, ,6,...,6, )
\end{verbatim}

Considerando apenas símbolos com freqüência maior que $3$, durante o processo de
segmentação, possibilita dividir a $TPS$ em várias regiões.

\end{itemize}

\section{Algoritmos}\label{sec:alg}

Nesta seção são apresentados os algoritmos desenvolvidos para tratar o
problema definido na Seção \ref{sec:probform}. Quais sejam:

\begin{itemize}
  \item{\textbf{$tagPathSequenceFilter()$}}. É o algoritmo
  principal, que recebe um arquivo HTML como entrada e retorna uma árvore DOM,
  podada, apenas com o conteúdo da região principal;
  \item{\textbf{$convertToSeq()$}}. Converte a árvore DOM de uma página
  $web$ para sua representação $TPS$;
  \item{\textbf{$searchRegion()$}}. A busca, propriamente dita, pela
  região principal da $TPS$;
  \item{\textbf{$filterAlphabet()$}}. Filtra um alfabeto, removendo os símbolos de
  menor freqüência, tornando o algoritmo de busca mais robusto e resistente ao ruído;
  \item{\textbf{$pruneDOMTree()$}}. Poda da árvore DOM original,
  deixando apenas o conteúdo da região principal encontrado com $searchRegion$,
  mantendo a estrutura do documento original.
\end{itemize}

\subsection{Algoritmo $tagPathSequenceFilter()$}

\begin{algorithm}[H]
\caption{Filtra o ruído de uma página $web$}
\label{alg:tpsfilter}
\textbf{Input:} $inputFile$ - um arquivo HTML \\
\textbf{Output:} árvore DOM de $inputFile$ podada
\begin{algorithmic}[1]
\Procedure{tagPathSequenceFilter}{$inputFile$}
\State $DOMTree \leftarrow parseHTML(inputFile)$
\State $convertToSeq(DOMTree.body,$`` ''$,TPS)$
\State $searchRegion(TPS)$
\State $pruneDOMTree(DOMTree.body,TPS)$
\State return $DOMTree$
\EndProcedure
\end{algorithmic}
\end{algorithm}

O procedimento $tagPathSequenceFilter()$ no Algoritmo \ref{alg:tpsfilter}
retorna a região principal de $inputFile$. O procedimento $parseHTML()$, na
Linha $2$, converte o código HTML em uma árvore DOM; $convertToSeq()$, na Linha
$3$, converte a árvore DOM em uma TPS; o procedimento $searchRegion()$, na Linha
$4$, procura recursivamente pela maior região da TPS que possui um alfabeto
único e, finalmente; $pruneDOMTree()$, na Linha $5$, retira da árvore DOM (poda)
todos os nós que não estão na TPS resultante, preservando a estrutura do
documento retornado na Linha $6$.

Abaixo são detalhados os algoritmos $convertToSeq()$, $searchRegion()$,
$filterAlphabet()$ e $pruneDOMTree()$. O algoritmo $parseHTML()$ não faz parte
do escopo deste trabalho, portanto não será discutido aqui.


\subsection{Algoritmo $convertToSeq()$}

\begin{algorithm}[H]
\caption{Converte uma árvore DOM para a representação de seqüência de $tag$ $path$}
\label{alg:tree2seq}
\textbf{Input:} $node$ - um nó da árvore DOM, inicialmente a raiz da árvore \\
\textbf{Input:} $tp$ - o $tag$ $path$ anterior, inicialmente vazio \\
\textbf{Input:} $TPS$ - a $TPS$ de uma árvore DOM, inicialmente vazia \\
\textbf{Output:} a $TPS$ de uma árvore DOM armazenada em $TPS$
\begin{algorithmic}[1]
\Procedure{convertToSeq}{node,tp,TPS by ref.}
\State $tp \leftarrow concat(tp,$``/''$,node.$tag$,node.style)$
\If {$tp \ni tagPathMap$}
\State $tagPathMap \leftarrow tagPathMap + \{tp\}$
\State $tagPathMap[tp].code \leftarrow tagPathMap.size$
\EndIf
\State $TPS \leftarrow concat(TPS,tagPathMap[tp].code);$
\For {each $child$ of $node$}
\State $convertToSeq(child,tp,TPS)$
\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}

O procedimento $convertToSeq()$ no Algoritmo \ref{alg:tree2seq} converte uma
página $web$ de sua representação em árvore DOM para uma representação em
formato TPS, percorrendo a árvore DOM em profundidade. Inicialmente é chamado no
Algoritmo \ref{alg:tpsfilter} com um $tag$ $path$ vazio como parâmetro, que
representa a $string$ do $tag$ $path$ anterior ($i.e.$ da chamada recursiva
anterior).
Na Linha $2$, o $tag$ $path$ anterior é concatenado com a $tag$ atual e com suas
definições de estilo, com objetivo de distinguir caminhos repetidos com estilos
diferentes; na Linha $3$, é verificado se o $tag$ $path$ atual já foi visto
antes pelo algoritmo ou não ($tagPathMap$ é utilizado para este propósito) e, se
não, na Linha $4$, ele é inserido no conjunto $tagPathMap$ e um novo código é
atribuído à ele na Linha $5$, como mostrado na Definição \ref{def:tps}; na Linha
$7$, o código do $tag$ $path$ é concatenado ao final da seqüência e, finalmente,
o procedimento é invocado recursivamente na Linha $9$ para cara filho de $node$.

\subsection{Algoritmo $searchRegion()$}

Este é o algoritmo central, já que é responsável por encontrar a região
principal, portanto incluímos uma ilustração, na Figura \ref{fig:alg}, para
facilitar seu entendimento. A Figura \ref{fig:alg} apresenta uma ilustração da
execução do algoritmo na qual foi omitido o procedimento de filtragem dos
símbolos com baixas freqüências para maior clareza, pois a intenção é passar a
idéia principal. Os detalhes e minúcias podem ser verificados na listagem do
algoritmo e na sua descrição.

\begin{figure}[H]
  \centering
    \includegraphics[scale=0.45]{alg-pb-pt.jpg}
  \caption{Ilustração da execução do algoritmo.}
  \label{fig:alg}
\end{figure}

%\begin{tiny}
\begin{algorithm}[H]
\caption{Busca regiões da TPS com alfabetos diferentes}
\label{alg:searchreg}
\textbf{Entrada:} $tagPathSequence$ - a $TPS$ de uma determinada página $web$ \\
\textbf{Saída:} a região principal da $TPS$, armazenada em $tagPathSequence$
\end{algorithm}
\begin{algorithmic}[1]
\Procedure{searchRegion}{$tagPathSequence[1..n]$ by reference}
\State $\Sigma \leftarrow \emptyset$ \Comment{alfabeto da seqüência}
\State $t \leftarrow 0$ \Comment{índice dos limiares de freqüência}
\For {$i \leftarrow 1..n$}
\State $sym \leftarrow tagPathSequence[i]$
\If {$sym \ni \Sigma$}
\State $\Sigma \leftarrow \Sigma \cup \{sym\}$
\State $symCount[sym] \leftarrow 0$
\EndIf
\State $symCount[sym] \leftarrow symCount[sym]+1$
\EndFor
\State $thresholds \leftarrow Ordered Set Of Frequencies(symCount)$
\State $regionFound \leftarrow false$
\While {not $regionFound$}
\State $t \leftarrow t + 1$
\State $curr\Sigma \leftarrow filterAlphabet(\Sigma,symCount,thresholds[t])$
\If {$curr\Sigma.size < 2$}
\State $break$
\EndIf
\State $currSymCount \leftarrow symCount$
\State $region\Sigma \leftarrow \emptyset$
\For {$i \leftarrow 1..n$}
\State $sym \leftarrow tagPathSequence[i]$
\If {$sym \in curr\Sigma$}
\State $region\Sigma \leftarrow region\Sigma \cup \{sym\}$
\State $currSymCount[sym] \leftarrow currSymCount[sym]-1$
\If {$currSymCount[sym] = 0$}
\State $curr\Sigma \leftarrow curr\Sigma - \{sym\}$
\If {$curr\Sigma \cap region\Sigma = \emptyset$}
\If {$(curr\Sigma \neq \emptyset) \wedge (n-2i)/n > 0.20$}
\State $regionFound \leftarrow true$
\EndIf
\State $break$
\EndIf
\EndIf
\EndIf
\EndFor
\EndWhile
\If {$regionFound$}
\If {$i < n/2$}
\State $tagPathSequence \leftarrow tagPathSequence[i+1..n]$
\Else
\State $tagPathSequence \leftarrow tagPathSequence[1..i]$
\EndIf
\State $searchRegion(tagPathSequence)$
\EndIf
\EndProcedure
\end{algorithmic}
%\end{algorithm}
% \end{tiny}

O procedimento $searchRegion()$ no Algoritmo \ref{alg:searchreg} calcula o
alfabeto da TPS e as freqüências correspondentes de cada símbolo nas Linhas $4$
a $11$; na Linha $12$, os limiares de freqüência, da Definição \ref{def:ft}, são
calculados; nas Linhas $14$ a $38$ é realizada a busca por uma posição na
seqüência onde é possível dividi-la ($i.e.$ onde existe uma região); na Linha
$15$ os limiares de freqüência são iterados; na Linha $16$ o alfabeto da TPS, da
Definição \ref{def:alpha}, é filtrado, como descrito na Seção
\ref{sec:probform}; na Linha $22$ a TPS é iterada; na Linha $25$ o alfabeto da
região é calculado e; nas Linhas $27$ a $35$ é verificado se existe uma
intersecção entre os alfabetos das duas partes da TPS (uma intersecção vazia
indica que uma possível região foi encontrada, como na Definição
\ref{def:region}). A região encontrada só é considerada válida se for ao menos
20\% maior que o restante da seqüência, caso contrário o filtro de freqüência é
iterado e a busca prossegue.
Este percentual é, na verdade, um parâmetro com o propósito de evitar relatar
uma região sob condições ambíguas (nos experimentos foi utilizado o valor de
20\%); finalmente nas Linhas $39$ a $46$ a TPS é dividida se uma região foi
encontrada, chamando o procedimento $searchRegion()$ recursivamente na Linha
$45$.

\subsection{Algoritmo $filterAlphabet()$}

\begin{algorithm}[H]
\caption{Filtra símbolos de baixa freqüência no alfabeto}
\label{alg:filteralpha}
\textbf{Input:} $\Sigma$ - alfabeto a ser filtrado \\
\textbf{Input:} $symCount$ - conjunto das freqüências ($FS$) dos símbolos de
$\Sigma$ \\
\textbf{Input:} $threshold$ - limiar de freqüência \\
\textbf{Output:} alfabeto filtrado
\begin{algorithmic}[1]
\Procedure{filterAlphabet}{$\Sigma$, symCount, threshold}
\State $filtered\Sigma \leftarrow \emptyset$
\For {$i \leftarrow 1..n$}
\If {$symCount[\Sigma[i]] \geq threshold$}
\State $filtered\Sigma \leftarrow filtered\Sigma \cup \{\Sigma[i]\}$
\EndIf
\EndFor
\State return $filtered\Sigma$
\EndProcedure
\end{algorithmic}
\end{algorithm}

O procedimento $filterAlphabet()$ no Algoritmo \ref{alg:filteralpha} remove do alfabeto
$\Sigma$, todo símbolo com freqüência inferior a $threshold$.
Nas Linhas $3$ to $7$ apenas os símbolos com freqüência maior ou igual a
$threshold$ são inseridos no conjunto resultante. O resultado de $filterAlphabet()$ é
utilizado no Algoritmo \ref{alg:searchreg}, Linha $24$, onde apenas os símbolos
em $curr\Sigma$ são considerados durante a busca pela região principal.

\subsection{Algoritmo $pruneDOMTree()$}

\begin{algorithm}[H]
\caption{Poda da árvore DOM nós que não pertencem à seqüência}
\label{alg:prune}
\textbf{Input:} $node$ - um nó da árvore DOM, inicialmente a raiz \\
\textbf{Input:} $sequence$ - a TPS que deve permanecer na árvore DOM \\
\textbf{Output:} árvore DOM podada, referenciada em $node$
\begin{algorithmic}[1]
\Procedure{pruneDOMTree}{$node$ by ref.,$sequence$}
\For {each child of node}
\If {$pruneDOMTree(child,sequence) = true$}
\State remove child from $node$
\EndIf
\EndFor
\If {$node \ni sequence$ and $node.childCount = 0$}
\State return $true$
\EndIf
\State return $false$
\EndProcedure
\end{algorithmic}
\end{algorithm}

O procedimento $pruneDOMTree()$ no Algoritmo \ref{alg:prune}, percorre a árvore
DOM, em profundidade, removendo os nós que não pertencem a $sequence$. Na Linha
$3$ a árvore DOM é percorrida; nas Linhas $7$ a $9$ é decidido se o nó $node$
deve ser removido ou não.

Um nó é removido da árvore, apenas se ele não está em $sequence$ \textbf{e} não
tem nenhum filho. Desta forma é possível manter a estrutura da árvore
remanescente intacta, evitando afetar, negativamente, a etapa subseqüente de
extração estruturada.

\section{Complexidade do Algoritmo}\label{sec:compl}

Com relação à complexidade do algoritmo, observando as Linhas $14$ e $22$ do
procedimento $searchRegion()$, pode-se ver que o laço de repetição da Linha $14$
itera os limiares de freqüência até encontrar uma região e na Linha $22$ a TPS,
filtrada em uma determina freqüência, é iterada, também, até encontrar uma
região e, se encontrada, a região é processada recursivamente.

No pior caso, quando a intersecção dos alfabetos só é vazia na última posição da
TPS, a complexidade é, no máximo, $O(n^2 f)$, onde $n$ é o tamanho da TPS e $f$
é o tamanho do conjunto $thresholds$. Na prática, o tamanho do conjunto
$thresholds$ e bem menor do que o tamanho da TPS, então é possível afirmar que a
complexidade de tempo se aproxima de $O(n^2)$ como mostrado na Equação
\ref{eq:w}.
  \begin{equation}\label{eq:w}
  T(n) = T(n - 1) + \Theta(n) \Longrightarrow \sum_{i=1}^{n}
  i = \frac{n(n+1)}{2} = O(n^2)
  \end{equation} 

Na média, se a TPS é dividida na metade, a complexidade é $O(n)$, como mostrado
na Equação \ref{eq:a}.
  \begin{equation}\label{eq:a}
  T(n) = T(n/2) + \Theta(n) \Longrightarrow \sum_{i=1}^{log_{2}^{n}}
  \frac{n}{2^i} = n - 1 = O(n)
  \end{equation} 

No melhor caso, a TPS é dividida na primeira posição, resultando em uma
complexidade de $O(n)$ como mostrado na Equação \ref{eq:b}.
  \begin{equation}\label{eq:b}
  T(n) = T(n - 1) + \Theta(1) \Longrightarrow \sum_{i=1}^{n} 1 = n = O(n)
  \end{equation} 


Em situações reais, como as que ocorreram na avaliação empírica do algoritmo,
as seqüências são divididas aproximadamente quatro ou cinco vezes até que não
seja mais possível dividi-las. Portanto, para situações reais, é possível
afirmar que o algoritmo possui complexidade de tempo $O(in)$, onde $n$ é o
tamanho da TPS e $i$ é o número de vezes que a seqüência é dividida, o qual
podemos considerar como sendo uma constante (sem impacto assintótico) e, sendo
assim, afirmar que a complexidade de tempo é $O(n)$.

\chapter{Resultados Experimentais}\label{ch:results}

Neste capítulo são descritos e discutidos os resultados dos experimentos e sua
realização.
Para obter os resultados apresentados na Subseção \ref{sub:res}, o algoritmo
proposto foi implementado e testado em vários $web$ $sites$ comerciais e
institucionais. Na Seção \ref{sec:clar} um destes resultados é detalhado, para
servir de exemplo, para esclarecer como eles foram compilados na Tabela
\ref{table:results}.

\section{Metodologia de avaliação dos resultados}\label{sec:met}

Para avaliar os resultados da técnica proposta, será utilizado o algoritmo MDR
\cite{MDR03}, uma conhecida técnica de extração estruturada. O resultado da
extração pura (apenas MDR) será considerado como $baseline$ para comparação com
o resultado da extração combinada com a técnica proposta de remoção de ruído.

A avaliação dos resultados é constituída das seguintes etapas:
\begin{itemize}
  \item escolha de uma técnica de extração automática de dados estruturados;
  \item definição de um conjunto de páginas para teste;
  \item aplicação da técnica de extração no conjunto de teste, documentando os
  resultados obtidos como \textit{target} (registro de interesse) ou
  \textit{noise} (ruído);
  \item nova aplicação da técnica de extração no mesmo conjunto de teste,
  mas desta vez filtrando-o antes, utilizando a técnica proposta neste trabalho,
  documentando os resultados da mesma maneira;
  \item comparação de ambos os resultados e medição do aumento/redução da
  precisão (remoção de ruído).
\end{itemize}

Para primeira etapa foi escolhido o MDR para realizar a extração, pois esta
técnica possui diversas implementações disponíveis, vários trabalhos publicados
a respeito, funciona em uma única página e os resultados da extração são
razoáveis para avaliar a técnica proposta neste trabalho. Outras técnicas
poderiam ser utilizadas, se estivessem disponíveis, e desde que não necessitem
de várias páginas HTML como entrada ($e.g.$ $RoadRunner$
\cite{RRunner01}).


\section{Detalhamento dos Experimentos}\label{sec:clar}

Os resultados da extração obtidos utilizando apenas o MDR, foram considerados
como $baseline$ a ser comparado com os resultados obtidos através do uso
combinado da técnica proposta com o MDR, como ilustrado na Figura
\ref{fig:method}.
   
Quando ambas abordagens (MDR e filtragem TPS + MDR) são aplicadas a uma página
de busca com 20 resultados do $web$ $site$ ``YouTube'' (\#38), os seguintes
resultados são obtidos:

\begin{itemize}
\item{}página $web$ 'crua' ($i.e.$ página original, sem filtragem da TPS)
\begin{itemize}
\item{}árvore DOM processada: $1424$ nós;
\item{}resultados do MDR: $82$ registros no total ($62$ ruído/$20$ alvo);
\end{itemize}

\item{}página $web$ filtrada ($i.e.$ página após aplicação do filtro da
TPS)
\begin{itemize}
\item{}árvore DOM processada: $674$ nós, tamanho $47,33\%$ da página original,
redução de $-52,67\%$
\item{}resultados do MDR: $20$ registros no total ($0$ ruído/$20$ alvo), ruído
removido $100\%$
\end{itemize}
\end{itemize}

Neste resultado observa-se uma melhora na extração dos registros, assim como uma
redução considerável do tamanho da árvore DOM que precisou ser processada. Um
percentual de $52.67\%$ da árvore DOM foi podado sem que ocorresse a perda dos
registros de interesse (alvo) durante o processo. Tudo o que foi podado da
árvore, neste caso, era ruído. A Figura \ref{fig:ex2} ilustra a região principal
da página e a Figura \ref{fig:tps} mostra a respectiva TPS e a região principal
detectada pelo algoritmo proposto.

\begin{figure}[H]
  \centering
    \includegraphics[scale=0.32]{example2-gs-pt.jpg}
  \caption{Um página de resultados do $site$ YouTube com sua região principal
  delimitada.}
  \label{fig:ex2}
\end{figure}

\begin{figure}[H]
  \centering
    \includegraphics[scale=0.28]{tps-pt.jpg}
  \caption{A TPS de uma página do $site$ YouTube com a região principal que foi
  detectada pelo algoritmo.}
  \label{fig:tps}
\end{figure}


Sem aplicar o filtro na TPS, são obtidos $82$ registros no total e, como sabe-se
de antemão que existem $20$ registros de interesse nesta página, considera-se
que a quantidade de $62$ registros representam $100\%$ do ruído presente nesta
página e que deve ser removido. Quando o filtro é utilizado, desta vez são
obtidos apenas os $20$ registros de interesse na fase de extração, resultando em
uma precisão de $100\%$, o que significa que todo o ruído da página foi
removido, neste caso. O percentual de ruído removido é calculado como
\begin{equation}\label{eq:noise}
NoiseRemoved=1-\frac{\#Rec_{totalTPS}-\#Rec_{targetTPS}}{\#Rec_{total}-\#Rec_{target}}
\end{equation}
Onde $\#Rec_{total}$ e $\#Rec_{target}$ são o total de registros e o total de
registros de interesse, respectivamente, da página original, e
$\#Rec_{totalTPS}$ e $\#Rec_{targetTPS}$ são o total de registros e o total de
registro de interesse, respectivamente, da página $web$ filtrada.

\subsection{Resultados}\label{sub:res}

Na Tabela \ref{table:results} são apresentados, nas três primeiras colunas, o
tamanho da árvore DOM processada pelo MDR ($i.e.$ original) e a redução obtida
após remoção do ruído ($i.e.$ podado). A coluna ``Conteúdo principal'' indica se
o processo de remoção de ruído preservou a região principal ou não. As próximas
quatro colunas são os resultados obtidos com o MDR sem e com remoção de ruído
respectivamente, exibindo o total geral de registros extraídos e o total de
registros de interesse ($target$) extraídos para ambas abordagens. A última
coluna mostra o percentual de ruído removido, calculado conforme a Equação
\ref{eq:noise}.
 
\begin{table}[H]
\caption{Resultados}
\label{table:results}
\centering
\begin{tiny}
\begin{tabular}{r l r r r c r r r r r}
\hline\hline
& \multicolumn{5}{c}{} & \multicolumn{4}{c}{MDR (\# registros)} & (eq. \ref
{eq:noise})\\
& & \multicolumn{3}{c}{Tam. DOM (\# nós)} & Cont. & \multicolumn{2}{c}{Orig.}
& \multicolumn{2}{c}{Pruned} & Ruído\\
\# & $Site$ & Orig. & Podado & Red. & princ. & Tot & Tgt & Tot & Tgt & rem. \\
\hline
1 & ACM & 601 & 340 & -43,43\% & Sim & 61 & 10 & 16 & 10 & 88,24\% \\
2 & Amazon & 3499 & 1069 & -69,45\% & Sim & 344 & 16 & 41 & 16 & 92,38\% \\
3 & Apple & 1422 & 962 & -32,35\% & Sim & 63 & 15 & 23 & 15 & 83,33\% \\
4 & Avon & 911 & 575 & -36,88\% & Sim & 69 & 20 & 29 & 20 & 81,63\% \\
5 & Barnes \& Noble & 1242 & 778 & -37,36\% & Sim & 147 & 30 & 54 & 30 & 79,49\% \\
6 & Bestbuy & 3632 & 1425 & -60,77\% & Sim & 299 & 15 & 15 & 15 & 100,00\% \\
7 & Blockbuster & 2176 & 1381 & -36,53\% & Sim & 84 & 25 & 32 & 25 & 88,14\% \\
8 & Bondfaro & 3897 & 1820 & -53,30\% & Sim & 160 & 28 & 30 & 28 & 98,48\% \\
9 & Bradesco & 1913 & 1113 & -41,82\% & Sim & 164 & 10 & 93 & 10 & 46,10\% \\
10 & Build & 2712 & 746 & -72,49\% & Não & 117 & 12 & 69 & 0 & N/A \\
11 & Buscapé & 3608 & 1607 & -55,46\% & Sim & 223 & 24 & 24 & 24 & 100,00\% \\
12 & Costco & 4504 & 326 & -92,76\% & Não & 246 & 96 & 8 & 8 & N/A \\
13 & Dell & 1737 & 881 & -49,28\% & Sim & 177 & 12 & 64 & 12 & 68,48\% \\
14 & Disney & 2778 & 2006 & -27,79\% & Sim & 193 & 96 & 116 & 96 & 79,38\% \\
15 & Drugstore & 1774 & 850 & -52,09\% & Sim & 156 & 18 & 52 & 18 & 75,36\% \\
16 & eBay & 2623 & 1801 & -31,34\% & Sim & 162 & 50 & 50 & 50 & 100,00\% \\
17 & Elsevier & 906 & 160 & -82,34\% & Sim & 120 & 10 & 32 & 10 & 80,00\% \\
18 & Footlocker & 2440 & 1106 & -54,67\% & Sim & 238 & 60 & 60 & 60 & 100,00\% \\
19 & Gamestop & 1947 & 935 & -51,98\% & Não & 86 & 12 & 6 & 0 & N/A \\
20 & Gap & 2249 & 1365 & -39,31\% & Sim & 235 & 124 & 126 & 124 & 98,20\% \\
21 & Globo & 400 & 193 & -51,75\% & Sim & 80 & 10 & 20 & 10 & 85,71\% \\
22 & Globo G1 & 900 & 619 & -31,22\% & Não & 225 & 10 & 202 & 0 & N/A \\
23 & Google & 1421 & 474 & -66,64\% & Sim & 118 & 11 & 21 & 11 & 90,65\% \\
24 & Home Depot & 5199 & 1304 & -74,92\% & Sim & 325 & 24 & 24 & 24 & 100,00\% \\
25 & HP & 1783 & 1258 & -29,44\% & Sim & 71 & 15 & 15 & 15 & 100,00\% \\
26 & Itaú & 1111 & 410 & -63,10\% & Não & 77 & 10 & 11 & 0 & N/A \\
27 & Lojas Americanas & 2660 & 710 & -73,31\% & Sim & 211 & 20 & 20 & 20 & 100,00\% \\
28 & Macy's & 5676 & 2158 & -61,98\% & Não & 164 & 40 & 43 & 0 & N/A \\
29 & Magazine Luiza & 3167 & 1115 & -64,79\% & Sim & 314 & 40 & 44 & 40 & 98,54\% \\
30 & Mercadolivre & 2401 & 1771 & -26,24\% & Sim & 136 & 50 & 52 & 50 & 97,67\% \\
31 & Microsoft & 871 & 272 & -68,77\% & Sim & 57 & 16 & 16 & 16 & 100,00\% \\
32 & Newegg & 8481 & 3419 & -59,69\% & Não & 965 & 20 & 307 & 0 & N/A \\
33 & Nike & 4082 & 1829 & -55,19\% & Sim & 329 & 23 & 23 & 23 & 100,00\% \\
34 & Office Depot & 3363 & 1111 & -66,96\% & Sim & 108 & 24 & 38 & 24 & 83,33\% \\
35 & PC Mall & 4285 & 2548 & -40,54\% & Sim & 216 & 25 & 53 & 25 & 85,34\% \\
36 & Rakuten & 3386 & 2768 & -18,25\% & Sim & 112 & 35 & 61 & 35 & 66,23\% \\
37 & Ralph Lauren & 995 & 564 & -43,32\% & Sim & 46 & 12 & 12 & 12 & 100,00\% \\
38 & Reuters & 1202 & 198 & -83,53\% & Sim & 136 & 10 & 10 & 10 & 100,00\% \\
39 & Scopus & 4929 & 4688 & -4,89\% & Sim & 114 & 20 & 75 & 20 & 41,49\% \\
40 & Sears & 5726 & 3890 & -32,06\% & Sim & 397 & 50 & 75 & 50 & 92,80\% \\
41 & Sephora & 3022 & 1440 & -52,35\% & Sim & 365 & 60 & 60 & 60 & 100,00\% \\
42 & Sony & 2200 & 1316 & -40,18\% & Sim & 98 & 15 & 18 & 15 & 96,39\% \\
43 & Staples & 2959 & 1611 & -45,56\% & Sim & 178 & 24 & 24 & 24 & 100,00\% \\
44 & Submarino & 2389 & 1268 & -46,92\% & Sim & 116 & 20 & 22 & 20 & 97,92\% \\
45 & Terra & 869 & 588 & -32,34\% & Sim & 122 & 50 & 76 & 50 & 63,89\% \\
46 & Tiffany & 3899 & 2753 & -29,39\% & Não & 183 & 12 & 67 & 0 & N/A \\
47 & Valor Econômico & 514 & 126 & -75,49\% & Não & 55 & 10 & 2 & 0 & N/A \\
48 & Wal-Mart & 1576 & 808 & -48,73\% & Sim & 110 & 20 & 40 & 20 & 77,78\% \\
49 & Webmotors & 2119 & 1361 & -35,77\% & Sim & 113 & 14 & 19 & 14 & 94,95\% \\
50 & Yahoo! & 760 & 290 & -61,84\% & Sim & 67 & 10 & 10 & 10 & 100,00\% \\
51 & YouTube & 1424 & 674 & -52,67\% & Sim & 82 & 20 & 20 & 20 & 100,00\% \\
\hline
& Média/Total &  &  & -50,18\% & 82,35\%&  &  &  &  & 88,86\% \\
&             &  &  &          & 17,65\%&  &  &  &  &  \\
\hline

\end{tabular}
\end{tiny}
\end{table}
 
Como se pode observar na Tabela \ref{table:results}, o total da coluna
``Conteúdo principal'' indica que o algoritmo funcionou em 82,35\% dos casos e
removeu, com este conjunto de teste, uma média de 88,86\% de todo o ruído
presente nos dados, como mostra a média da coluna ``Ruído rem.''.

A média de 50,18\% de redução no tamanho da árvore DOM é um resultado
interessante. Primeiro, por que significa que quase metade da árvore DOM é
ruído, na média. Segundo, por que este valor ficou bem próximo do valor
relatado, de forma independente, em \citeonline{Volume05} como sendo o tamanho
do ``template'' das páginas (em torno de 50\%).

Uma situação que chama a atenção na Tabela \ref{table:results} é o resultado
obtido para a página do $site$ ``Build'' (\#10). Sem filtrar o ruído, o MDR
retornou um total de $117$ registros, incluindo os $12$ registros de interesse.
Após aplicar o filtro de ruído, um total de $69$ registros são retornados,
nenhum deles de interesse, todos ruído. Então, após a filtragem, se a árvore
retornada fosse, na realidade, o seu complemento, o resultado seria de $48$
registros no total ($117-69=48$), incluindo os $12$ registros de interesse, o
que seria um bom resultado já que significa uma remoção de 65,71\% do ruído. O
que se pode deduzir disto é que, a segmentação da página ocorreu corretamente,
apenas a identificação da região principal falhou, já que neste caso, era
relativamente pequena.

Como conseqüência da remoção de ruído, podemos observar um aumento considerável
na precisão média da extração, como relatado na tabela \ref{table:prec}. A
redução no $recall$ corresponde às situações onde o filtro falhou, as quais são
discutidos e tratados na Subseção \ref{sub:disc}, e, apesar desta redução, as
medidas F e G apresentaram melhora significativa.

\begin{table}[H]
\centering
\caption{Precisão, $recall$, F-$measure$ e G-$measure$.}
\label{table:prec}
\begin{tabular}{l l l l}
\hline\hline
& MDR ($a$) & MDR+filtro ($b$) & Variação ($b-a$)\\
\hline
Precisão & 18,93\%  & 75,08\% & 56,15\% \\
$Recall$   & 100,00\% & 82,35\% & -17,65\% \\
F-$measure$ & 31,83\% & 78,55\% & 46,72\% \\
G-$measure$ & 43,51\% & 78,63\% & 35,13\% \\
\hline
\end{tabular}
\end{table}

\subsection{Discussão dos Resultados}\label{sub:disc}

Existem três situações principais onde o algoritmo poderia ser melhorado e,
destas, apenas duas podem levar a perda de conteúdo de interesse. Na Tabela
\ref{table:results}, coluna ``Conteúdo principal'', estas duas situações são
responsáveis por 17,65\% dos casos, onde o conteúdo principal foi removido
durante o processo de filtragem.

\begin{enumerate}
  \item{\textbf{páginas com \textit{templates} muito homogêneos}}. São páginas
  com pouca diferença entre as regiões. Neste caso, utilizando a técnica
  proposta, não resta muito a fazer, pois simplesmente não há informação
  suficiente para uma diferenciação entre as regiões da página, já que todas se
  parecem. Não são perdidos registros de interesse, mas a quantidade total de
  ruído removido é baixa;
  \item{\textbf{páginas com \textit{templates} muito heterogêneos}}. São paginas
  onde o conteúdo principal é subdividido em mais de uma região. Neste caso, a
  região principal acaba por ser dividida várias vezes durante o processo de
  filtragem e apenas a parte maior acaba passando pelo filtro (e ainda assim,
  pode ser que seja ruído). Mais a frente é proposta uma forma de contornar
  este problema;
  \item{\textbf{páginas com região principal menor que o restante}}. Este
  problema é uma conseqüência da segunda hipótese levantada na Seção 
  \ref{sec:probform}: ``a região principal é mais densa, ou maior, que as demais
  regiões''. Neste caso, ruído sempre será retornado no lugar do conteúdo
  principal. A mesma proposta apresentada para situação anterior também pode ser
  utilizada neste caso.
\end{enumerate}

No caso de \textit{templates} heterogêneos, a filtragem da TPS ainda pode ser
utilizada realizando algumas modificações no algoritmo. Um exemplo de
\textit{template} heterogêneo são os $sites$ de notícias, onde cada registro de
interesse tem uma estrutura diferente, mas todos pertencem ao mesmo domínio
($i.e.$ pertencem à mesma entidade). Nesta situação específica, a segmentação da
TPS ainda pode ser utilizada para segmentar a página em diferentes regiões, e
uma abordagem semântica pode ser usada para combinar as várias regiões de
interesse, retornando um conjunto de regiões como resultado e não apenas uma
única região.
 
Para a situação descrita para o $site$ ``Build'' (que ocorreu, também, em outros
oito $sites$, ou seja, em 17,65\% dos casos), quando a região principal é menor
que as demais, uma abordagem semântica também pode ser utilizada para validar se
a região encontrada, de fato, possui conteúdo de interesse e, se não possuir
deve ser descartada e a árvore complementar ($i.e.$ inverter a poda) deve ser
retornada em seu lugar. O algoritmo principal ficaria assim:

\begin{algorithm}[H]
\caption{Filtra o ruído de uma página $web$}
\label{alg:tpsfilter2}
\textbf{Input:} $inputFile$ - um arquivo HTML \\
\textbf{Output:} árvore DOM de $inputFile$ podada
\begin{algorithmic}[1]
\Procedure{tagPathSequenceFilter}{$inputFile$}
\State $DOMTree \leftarrow parseHTML(inputFile)$
\State $convertToSeq(DOMTree.body,$`` ''$,TPS)$
\State $backupTPS \leftarrow TPS$
\State $searchRegion(TPS)$
\If {$TPS$ not $content$}
\State $TPS = backupTPS - TPS$   
\EndIf
\State $pruneDOMTree(DOMTree.body,TPS)$
\State return $DOMTree$
\EndProcedure
\end{algorithmic}
\end{algorithm}

Algoritmo \ref{alg:tpsfilter2} é igual ao Algoritmo \ref{alg:tpsfilter}, exceto
pela Linha $6$ onde é verificado se o conteúdo principal está presente na região
e, caso não esteja, a seqüência complementar é utilizada (Linha $7$), garantindo
a presença do conteúdo principal.

Técnicas como a apresentada em \citeonline{Adaptive07}, que classifica uma
seqüência de blocos como sendo conteúdo ou não, pode ser utilizada para
implementar a Linha $6$ do algoritmo \ref{alg:tpsfilter2}.

\chapter{Conclusões e Trabalhos Futuros}\label{ch:conclusion}

Como mostrado nos resultados, o método proposto para segmentação da página e
remoção do ruído foi bastante efetivo em várias páginas
comerciais/institucionais.
Na maioria dos casos uma grande quantidade de ruído foi removido sem comprometer
os registros de interesse. Também, quando aplicada em conjunto com o MDR, foi
observado um incremento considerável na precisão da extração e na qualidade
geral da extração ($e.g.$ aumento do f-measure de 31,83\% para 78,55\%).

Nas situações em que o método proposto atua aquém das expectativas, outras
técnicas podem ser combinadas dependendo da aplicação. Em casos extremos, onde a
página possuir estrutura muito homogênea (de forma que não seja possível
encontrar as diferentes regiões) ou muito heterogênea (onde o conteúdo principal
está espalhado em diversas regiões diferentes), o conteúdo principal poderia,
talvez, ser detectado através do uso de uma técnica semântica.

O método mostrou excelente performance, pois apresentou resultados
satisfatórios para a maioria dos $sites$ comerciais nos quais foi testado. Ele
também supera as limitações (necessidade de treinamento, dependência de $tags$
HTML, anotações manuais, entre outras) de trabalhos anteriores na área de
limpeza, remoção de ruído e segmentação de página, como mencionado no Capítulo
\ref{ch:rev}.

Uma sugestão para trabalho futuro seria encontrar maneiras de adaptar/corrigir o
método para melhorar seus resultados nas seguintes situações:
\begin{itemize}
  \item páginas que apresentem estrutura muito heterogênea: encontrar uma forma
  de agrupar as várias regiões principais em uma só;
  \item páginas que apresentem estrutura muito homogênea: encontrar uma forma
  de diferenciar o ruído da região principal;
  \item páginas onde a região principal tem tamanho inferior ao ruído total:
  identificar a região principal através de outros atributos que não o tamanho.
\end{itemize}

Este trabalho também foi publicado no \textit{JIDM - Journal of Information and
Data Management} no ano de 2013, como artigo completo \cite{TPS2013}, e os
algoritmos descritos neste trabalho foram implementados em linguagem
\textit{C++} e $M$ (MatLab/Octave) e estão disponíveis para acesso.

\bibliographystyle{ufscThesis/ufsc-alf}
\bibliography{refs}

%\apendice
%\chapter{Tabela de resultados}

\end{document}
